from tools.download_html import fetch_and_save_html
from tools.search import fetch_search_results
import pandas as pd
import os
import json
import time

if __name__ == "__main__":
    # Äá»c file Excel chá»©a danh sÃ¡ch nghá»‹ Ä‘á»‹nh
    df = pd.read_excel("./resolutions.xlsx")
    df["NgÃ y hiá»‡u lá»±c"] = pd.to_datetime(df["NgÃ y hiá»‡u lá»±c"], format="%d/%m/%Y", errors="coerce")
    df["Nghá»‹ Ä‘á»‹nh sá»‘"] = df["Nghá»‹ Ä‘á»‹nh sá»‘"].astype(str)

    # Lá»c nghá»‹ Ä‘á»‹nh cÃ³ hiá»‡u lá»±c trÆ°á»›c 2006
    df = df[(df["NgÃ y hiá»‡u lá»±c"] > "2005-01-01")]

    # Láº¥y danh sÃ¡ch nghá»‹ Ä‘á»‹nh vÃ  ná»™i dung
    NDS = df["Nghá»‹ Ä‘á»‹nh sá»‘"].tolist()
    Content = df["Ná»™i dung"].tolist()
    active_date = df["NgÃ y hiá»‡u lá»±c"].tolist()

    # ThÆ° má»¥c lÆ°u HTML vÃ  mapping
    save_dir = "html_pages"
    mapping_filename = "mapping.json"

    # Duyá»‡t tá»«ng nghá»‹ Ä‘á»‹nh
    for idx, (nd, content, date) in enumerate(zip(NDS, Content, active_date)):
        print(f"\nğŸ” Äang xá»­ lÃ½: {nd} - {content[:50]}...")

        try:
            # TÃ¬m kiáº¿m Google
            deal, urls = fetch_search_results(deal=nd, context=content, num_results=5, lang="vi")
            thuvienphapluat_urls = [url for url in urls if "thuvienphapluat" in url]

            if not thuvienphapluat_urls:
                print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y URL thuvienphapluat.")
                print(urls)
                continue
            
            

            # Táº£i URL Ä‘áº§u tiÃªn thá»a mÃ£n
            index_url_tuple = (idx, thuvienphapluat_urls[0])
            result = fetch_and_save_html(index_url_tuple, save_dir=save_dir, mapping_filename=mapping_filename)
            print(f"âœ… ÄÃ£ lÆ°u: {result[1]} cho URL: {result[0]}")
            url, filename = result

            # Sau khi fetch xong thÃ¬ ghi thÃªm active_date vÃ o mapping
            mapping_path = os.path.join(save_dir, mapping_filename)

            try:
                with open(mapping_path, "r", encoding="utf-8") as mf:
                    mapping = json.load(mf)
                    mapping[url]["active_date"] = str(date)  # date lÃ  biáº¿n tÆ°Æ¡ng á»©ng tá»« vÃ²ng láº·p

                    with open(mapping_path, "w", encoding="utf-8") as mf:
                        json.dump(mapping, mf, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"âŒ Lá»—i khi cáº­p nháº­t active_date cho {url}: {e} : {date}")

        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ {nd}: {e}")

    # # In Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i Ä‘áº¿n thÆ° má»¥c lÆ°u
    # abs_path = os.path.abspath(save_dir)
    # print(f"\nğŸ“ HTML pages vÃ  mapping.json Ä‘Ã£ lÆ°u táº¡i: {abs_path}")
